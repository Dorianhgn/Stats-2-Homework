{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bce59eb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "library('tidyverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f96f5d3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m3\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \"\\t\"\n",
      "\u001b[32mdbl\u001b[39m (3): weight, mpg, foreign\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data <- read_tsv(\"podatki_7.txt\", col_names = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b913b31",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>weight</th><th scope=col>mpg</th><th scope=col>foreign</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>4100</td><td>18</td><td>0</td></tr>\n",
       "\t<tr><td>2720</td><td>47</td><td>0</td></tr>\n",
       "\t<tr><td>3760</td><td>13</td><td>1</td></tr>\n",
       "\t<tr><td>2530</td><td>19</td><td>1</td></tr>\n",
       "\t<tr><td>4720</td><td>47</td><td>0</td></tr>\n",
       "\t<tr><td>3210</td><td>41</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " weight & mpg & foreign\\\\\n",
       " <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 4100 & 18 & 0\\\\\n",
       "\t 2720 & 47 & 0\\\\\n",
       "\t 3760 & 13 & 1\\\\\n",
       "\t 2530 & 19 & 1\\\\\n",
       "\t 4720 & 47 & 0\\\\\n",
       "\t 3210 & 41 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| weight &lt;dbl&gt; | mpg &lt;dbl&gt; | foreign &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 4100 | 18 | 0 |\n",
       "| 2720 | 47 | 0 |\n",
       "| 3760 | 13 | 1 |\n",
       "| 2530 | 19 | 1 |\n",
       "| 4720 | 47 | 0 |\n",
       "| 3210 | 41 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  weight mpg foreign\n",
       "1 4100   18  0      \n",
       "2 2720   47  0      \n",
       "3 3760   13  1      \n",
       "4 2530   19  1      \n",
       "5 4720   47  0      \n",
       "6 3210   41  0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166f4cc",
   "metadata": {},
   "source": [
    "### 7.a. Likelihood Function\n",
    "For each car:\n",
    "- $Y_i = \\text{foreign}_i \\in \\{0, 1\\}$\n",
    "- $p_i = 1 - exp(-exp(\\beta_0 + \\beta_1 \\text{weight}_i + \\beta_2 \\text{mpg}_i))$\n",
    "\n",
    "- $Y_i \\sim \\text{Bernoulli}(p_i)$\n",
    "\n",
    "Assuming independent observations, the likelihood function is given by:\n",
    "$$\n",
    "L(\\beta_0, \\beta_1, \\beta_2) = \\prod_{i=1}^{n} p_i^{Y_i} (1 - p_i)^{1 - Y_i}\n",
    "$$\n",
    "where $n$ is the number of cars.\n",
    "\n",
    "The log-likelihood function is:\n",
    "$$\n",
    "\\ell(\\beta_0, \\beta_1, \\beta_2) = \\sum_{i=1}^{n} \\left( Y_i \\log(p_i) + (1 - Y_i) \\log(1 - p_i) \\right)$$\n",
    "\n",
    "The negative of this function is called the *log-loss* used in neural networks for classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30792545",
   "metadata": {},
   "source": [
    "### 7.b. Estimate the Parameters using Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "Since this function is the negative of the classical log-loss, we can fit a logistic regression model, specifying the link function this one. It will automatically find the best $\\beta_0, \\beta_1, \\beta_2$ parameters that maximize the log-likelihood function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c31b2df",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = foreign ~ ., family = binomial(link = \"cloglog\"), \n",
       "    data = data)\n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  7.1159225  1.5112535   4.709 2.49e-06 ***\n",
       "weight      -0.0021187  0.0004258  -4.975 6.51e-07 ***\n",
       "mpg         -0.0915402  0.0244097  -3.750 0.000177 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 107.855  on 99  degrees of freedom\n",
       "Residual deviance:  61.529  on 97  degrees of freedom\n",
       "AIC: 67.529\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg.log <- glm(foreign ~ ., data = data, family = binomial(link = \"cloglog\"))\n",
    "summary(reg.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafc8cc",
   "metadata": {},
   "source": [
    "The estimated coefficients are:\n",
    "  - $\\hat{\\beta_0} = 7.1 \\pm 1.5$\n",
    "  - $\\hat{\\beta_1} = (-2.11 \\pm 0.43) {\\times} 10^{-3} $\n",
    "  - $\\hat{\\beta_2} = (-9.2 \\pm 2.4) {\\times} 10^{-3}$\n",
    "\n",
    "For all coefficients, the p-values are $\\ll 0.05$, indicating strong evidence that these explanatory variables are associated with the probability of a car being foreign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5ff69",
   "metadata": {},
   "source": [
    "### 7.c Fisher's Information Matrix\n",
    "\n",
    "The Fisher Information Matrix is given by the second derivative of the log-likelihood function with respect to the parameters. The diagonal values show how well each parameter is estimated: larger values mean higher information and hence smaller standard error for the estimate. Off-diagonal values show correlation between estimates: large absolute values mean that changes in one parameter’s estimate tend to go with changes in another.\n",
    "\n",
    "For each parameter $\\beta_j$, the Fisher Information Matrix is given by:\n",
    "\n",
    "$$\n",
    "[I(\\beta)]_{jk} = -E\\left[\\frac{\\partial^2 \\ell(\\beta)}{\\partial \\beta_j \\partial \\beta_k^T}\\right]\n",
    "$$\n",
    "\n",
    "This matrix is exactly the inverse of the covariance matrix of the parameter estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f8b445",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>(Intercept)</th><th scope=col>weight</th><th scope=col>mpg</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>   18.54474</td><td>    45300.6</td><td>    500.2597</td></tr>\n",
       "\t<tr><th scope=row>weight</th><td>45300.59696</td><td>118233653.4</td><td>1153114.8280</td></tr>\n",
       "\t<tr><th scope=row>mpg</th><td>  500.25968</td><td>  1153114.8</td><td>  15800.0761</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & (Intercept) & weight & mpg\\\\\n",
       "\\hline\n",
       "\t(Intercept) &    18.54474 &     45300.6 &     500.2597\\\\\n",
       "\tweight & 45300.59696 & 118233653.4 & 1153114.8280\\\\\n",
       "\tmpg &   500.25968 &   1153114.8 &   15800.0761\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | (Intercept) | weight | mpg |\n",
       "|---|---|---|---|\n",
       "| (Intercept) |    18.54474 |     45300.6 |     500.2597 |\n",
       "| weight | 45300.59696 | 118233653.4 | 1153114.8280 |\n",
       "| mpg |   500.25968 |   1153114.8 |   15800.0761 |\n",
       "\n"
      ],
      "text/plain": [
       "            (Intercept) weight      mpg         \n",
       "(Intercept)    18.54474     45300.6     500.2597\n",
       "weight      45300.59696 118233653.4 1153114.8280\n",
       "mpg           500.25968   1153114.8   15800.0761"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sigma <- vcov(reg.log)\n",
    "fisher_information_matrix <- solve(Sigma)\n",
    "fisher_information_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1012b79",
   "metadata": {},
   "source": [
    "**Interpretation:**  \n",
    "The large value on the diagonal for `weight` (1.18e8) means that the data give us a lot of information about how car weight affects the probability of a car being foreign, so this coefficient is estimated quite precisely. The noticeable off-diagonal entries, like the ones between `weight` and the intercept (45,300), and between `weight` and `mpg` (1.15e6), tell us that the uncertainties for these parameter estimates are related. In other words, if our estimate for one parameter changes, the estimate for the other might also shift in a way that still keeps the model fitting the data well.\n",
    "\n",
    "This doesn't mean our estimates are unreliable, since all the diagonal values are large, all the coefficients are still estimated accurately. It just means that the uncertainties in some parameters are somewhat connected, which is pretty normal in regression when predictors are not completely independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a8a84",
   "metadata": {},
   "source": [
    "### 7.d. Standard Errors of the Estimates\n",
    "\n",
    "The standard errors of the estimates are obtained from the square root of the diagonal elements of the inverse of the Fisher Information Matrix. These standard errors can be used to construct confidence intervals for the parameter estimates.\n",
    "\n",
    "We can check if they match the standard errors obtained from the logistic regression model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11ec511c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (Intercept)       weight          mpg \n",
      "1.5112535414 0.0004258285 0.0244097418 \n"
     ]
    }
   ],
   "source": [
    "variances <- sqrt(diag(Sigma))\n",
    "print(variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc02b0",
   "metadata": {},
   "source": [
    "These standard errors are the same as those obtained from the logistic regression model summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2689b",
   "metadata": {},
   "source": [
    "### 7.e. Test $\\mathcal{H}_0: \\beta_1 = \\beta_2 = 0$ with a Likelihood Ratio Test\n",
    "\n",
    "The LRT statistic is given by:\n",
    "\n",
    "$$\n",
    "\\Lambda = -2 \\left( \\ell(\\hat{\\beta}) - \\ell(\\hat{\\beta}_0) \\right)$$\n",
    "\n",
    "where $\\ell(\\hat{\\beta})$ is the log-likelihood of the full model and $\\ell(\\hat{\\beta}_0)$ is the log-likelihood of the reduced model (with $\\beta_1 = \\beta_2 = 0$).\n",
    "\n",
    "This statistic is asymptotically distributed as a chi-squared distribution with degrees of freedom equal to the number of constraints in the null hypothesis, which is 2 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07f96237",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = foreign ~ 1, family = binomial(link = \"cloglog\"), \n",
       "    data = data)\n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  -1.3418     0.2091  -6.417 1.39e-10 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 107.86  on 99  degrees of freedom\n",
       "Residual deviance: 107.86  on 99  degrees of freedom\n",
       "AIC: 109.86\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the restricted model\n",
    "reg.log.restricted <- glm(foreign ~ 1, data = data, family = binomial(link = \"cloglog\"))\n",
    "summary(reg.log.restricted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12dbb384",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log Lik.' 8.718793e-11 (df=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract the log-likelihoods of both models\n",
    "logLik_full <- logLik(reg.log)\n",
    "logLik_restricted <- logLik(reg.log.restricted)\n",
    "\n",
    "# calculate the likelihood ratio statistic\n",
    "likelihood_ratio_statistic <- -2 * (logLik_restricted - logLik_full)\n",
    "\n",
    "# calculate the p-value\n",
    "p_value <- pchisq(likelihood_ratio_statistic, df = 2, lower.tail = FALSE)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f630abb",
   "metadata": {},
   "source": [
    "The p-value $\\approx 8.72 {\\times} 10^{-5} \\ll 0.05$ indicates strong evidence against the null hypothesis, suggesting that at least one of the coefficients $\\beta_1$ or $\\beta_2$ is significantly different from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c650d80",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
